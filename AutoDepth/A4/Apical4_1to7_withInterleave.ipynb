{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.models import load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Lambda\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras import applications\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers, callbacks\n",
    "from keras import regularizers\n",
    "import math\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#import cv2\n",
    "\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "session = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 256, 256 \n",
    "crop_size = (256, 256)\n",
    "\n",
    "base_model_path = 'model_best.h5'\n",
    "\n",
    "train_data_dir ='Apical4_AdditionalDepths_Only_1to7_WithInterleave/Train'\n",
    "validation_data_dir ='Apical4_AdditionalDepths_Only_1to7_WithInterleave/Validation'\n",
    "test_data_dir ='Apical4_AdditionalDepths_Only_1to7_WithInterleave/Test'\n",
    "\n",
    "\n",
    "# number of epochs to train top model\n",
    "nepochs = 40 \n",
    "\n",
    "# batch size used by flow_from_directory and predict_generator\n",
    "batch_size=32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model1 = load_model(base_model_path)\n",
    "#base_model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model = Model(inputs=base_model1.input, outputs=base_model1.get_layer('mixed10').output)\n",
    "#base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_subtract(img):   \n",
    "#     img = tf.subtract(img, 35.5161)\n",
    "    img = tf.subtract(img, 41.89329/255.0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13969 images belonging to 7 classes.\n",
      "Found 3344 images belonging to 7 classes.\n",
      "7\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "WARNING:tensorflow:From F:\\Users\\boopla00\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From F:\\Users\\boopla00\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From F:\\Users\\boopla00\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 12)                21826796  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                832       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 21,828,083\n",
      "Trainable params: 21,793,651\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n",
      "[INFO] compile...\n",
      "[INFO] model fit...\n",
      "Epoch 1/40\n",
      "436/436 [==============================] - 6597s 15s/step - loss: 1.2806 - acc: 0.4680 - val_loss: 0.8330 - val_acc: 0.5478\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.54778, saving model to MyApical4Depth_additionaldepths_only_1to7_withInterleave.h5\n",
      "Epoch 2/40\n",
      "436/436 [==============================] - 6554s 15s/step - loss: 0.9289 - acc: 0.5490 - val_loss: 0.7565 - val_acc: 0.5737\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.54778 to 0.57367, saving model to MyApical4Depth_additionaldepths_only_1to7_withInterleave.h5\n",
      "Epoch 3/40\n",
      "436/436 [==============================] - 6543s 15s/step - loss: 0.8500 - acc: 0.5910 - val_loss: 0.8051 - val_acc: 0.5525\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.57367\n",
      "Epoch 4/40\n",
      "436/436 [==============================] - 6545s 15s/step - loss: 0.7182 - acc: 0.6603 - val_loss: 0.5048 - val_acc: 0.6793\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.57367 to 0.67935, saving model to MyApical4Depth_additionaldepths_only_1to7_withInterleave.h5\n",
      "Epoch 5/40\n",
      "436/436 [==============================] - 7066s 16s/step - loss: 0.5652 - acc: 0.7632 - val_loss: 0.3957 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.67935 to 0.85417, saving model to MyApical4Depth_additionaldepths_only_1to7_withInterleave.h5\n",
      "Epoch 6/40\n",
      "436/436 [==============================] - 6532s 15s/step - loss: 0.4580 - acc: 0.8061 - val_loss: 0.3486 - val_acc: 0.8219\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.85417\n",
      "Epoch 7/40\n",
      "436/436 [==============================] - 6550s 15s/step - loss: 0.4028 - acc: 0.8231 - val_loss: 0.3354 - val_acc: 0.8176\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.85417\n",
      "Epoch 8/40\n",
      "436/436 [==============================] - 6516s 15s/step - loss: 0.3741 - acc: 0.8330 - val_loss: 0.3197 - val_acc: 0.8481\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.85417\n",
      "Epoch 9/40\n",
      "436/436 [==============================] - 6583s 15s/step - loss: 0.3441 - acc: 0.8367 - val_loss: 0.3197 - val_acc: 0.8451\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.85417\n",
      "Epoch 10/40\n",
      "436/436 [==============================] - 6478s 15s/step - loss: 0.3324 - acc: 0.8433 - val_loss: 0.3047 - val_acc: 0.8530\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.85417\n",
      "Epoch 11/40\n",
      "436/436 [==============================] - 6553s 15s/step - loss: 0.2980 - acc: 0.8652 - val_loss: 0.2795 - val_acc: 0.8841\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.85417 to 0.88406, saving model to MyApical4Depth_additionaldepths_only_1to7_withInterleave.h5\n",
      "Epoch 12/40\n",
      "436/436 [==============================] - 6617s 15s/step - loss: 0.2644 - acc: 0.9156 - val_loss: 0.2084 - val_acc: 0.9529\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.88406 to 0.95290, saving model to MyApical4Depth_additionaldepths_only_1to7_withInterleave.h5\n",
      "Epoch 13/40\n",
      "436/436 [==============================] - 6487s 15s/step - loss: 0.2220 - acc: 0.9452 - val_loss: 0.1610 - val_acc: 0.9598\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.95290 to 0.95984, saving model to MyApical4Depth_additionaldepths_only_1to7_withInterleave.h5\n",
      "Epoch 14/40\n",
      "436/436 [==============================] - 6470s 15s/step - loss: 0.1890 - acc: 0.9551 - val_loss: 0.1615 - val_acc: 0.9589\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.95984\n",
      "Epoch 15/40\n",
      "436/436 [==============================] - 6378s 15s/step - loss: 0.1727 - acc: 0.9581 - val_loss: 0.1865 - val_acc: 0.9538\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.95984\n",
      "Epoch 16/40\n",
      "436/436 [==============================] - 6438s 15s/step - loss: 0.1615 - acc: 0.9624 - val_loss: 0.1419 - val_acc: 0.9595\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.95984\n",
      "Epoch 17/40\n",
      "436/436 [==============================] - 6478s 15s/step - loss: 0.1539 - acc: 0.9647 - val_loss: 0.1476 - val_acc: 0.9589\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.95984\n",
      "Epoch 18/40\n",
      "436/436 [==============================] - 6561s 15s/step - loss: 0.1448 - acc: 0.9661 - val_loss: 0.1418 - val_acc: 0.9635\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.95984 to 0.96347, saving model to MyApical4Depth_additionaldepths_only_1to7_withInterleave.h5\n",
      "Epoch 19/40\n",
      "436/436 [==============================] - 6792s 16s/step - loss: 0.1341 - acc: 0.9685 - val_loss: 0.1167 - val_acc: 0.9710\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.96347 to 0.97101, saving model to MyApical4Depth_additionaldepths_only_1to7_withInterleave.h5\n",
      "Epoch 20/40\n",
      "436/436 [==============================] - 6600s 15s/step - loss: 0.1290 - acc: 0.9703 - val_loss: 0.1100 - val_acc: 0.9659\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.97101\n",
      "Epoch 21/40\n",
      "436/436 [==============================] - 6796s 16s/step - loss: 0.1190 - acc: 0.9711 - val_loss: 0.1092 - val_acc: 0.9683\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.97101\n",
      "Epoch 22/40\n",
      "436/436 [==============================] - 6806s 16s/step - loss: 0.1152 - acc: 0.9723 - val_loss: 0.0978 - val_acc: 0.9692\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.97101\n",
      "Epoch 23/40\n",
      "436/436 [==============================] - 6799s 16s/step - loss: 0.1216 - acc: 0.9708 - val_loss: 0.1174 - val_acc: 0.9629\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.97101\n",
      "Epoch 24/40\n",
      "436/436 [==============================] - 6396s 15s/step - loss: 0.1093 - acc: 0.9743 - val_loss: 0.1003 - val_acc: 0.9695\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.97101\n",
      "Epoch 25/40\n",
      "436/436 [==============================] - 6730s 15s/step - loss: 0.0998 - acc: 0.9764 - val_loss: 0.1312 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.97101\n",
      "Epoch 26/40\n",
      "436/436 [==============================] - 6427s 15s/step - loss: 0.1023 - acc: 0.9761 - val_loss: 0.0987 - val_acc: 0.9707\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.97101\n",
      "Epoch 27/40\n",
      "436/436 [==============================] - 6426s 15s/step - loss: 0.0895 - acc: 0.9793 - val_loss: 0.0970 - val_acc: 0.9740\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.97101 to 0.97403, saving model to MyApical4Depth_additionaldepths_only_1to7_withInterleave.h5\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436/436 [==============================] - 6444s 15s/step - loss: 0.0883 - acc: 0.9791 - val_loss: 0.1389 - val_acc: 0.9580\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.97403\n",
      "Epoch 29/40\n",
      "436/436 [==============================] - 6425s 15s/step - loss: 0.0990 - acc: 0.9769 - val_loss: 0.1144 - val_acc: 0.9686\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.97403\n",
      "Epoch 30/40\n",
      "436/436 [==============================] - 6427s 15s/step - loss: 0.0880 - acc: 0.9792 - val_loss: 0.1072 - val_acc: 0.9662\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.97403\n",
      "Epoch 31/40\n",
      "436/436 [==============================] - 6540s 15s/step - loss: 0.0846 - acc: 0.9806 - val_loss: 0.1078 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.97403\n",
      "Epoch 32/40\n",
      "436/436 [==============================] - 6747s 15s/step - loss: 0.0789 - acc: 0.9820 - val_loss: 0.1027 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.97403\n",
      "Epoch 33/40\n",
      "436/436 [==============================] - 6663s 15s/step - loss: 0.0794 - acc: 0.9823 - val_loss: 0.1208 - val_acc: 0.9641\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.97403\n",
      "Epoch 34/40\n",
      "436/436 [==============================] - 6894s 16s/step - loss: 0.0844 - acc: 0.9786 - val_loss: 0.0951 - val_acc: 0.9692\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.97403\n",
      "Epoch 35/40\n",
      "436/436 [==============================] - 6693s 15s/step - loss: 0.0747 - acc: 0.9822 - val_loss: 0.0997 - val_acc: 0.9698\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.97403\n",
      "Epoch 36/40\n",
      "436/436 [==============================] - 6650s 15s/step - loss: 0.0693 - acc: 0.9827 - val_loss: 0.0897 - val_acc: 0.9725\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.97403\n",
      "Epoch 37/40\n",
      "436/436 [==============================] - 6613s 15s/step - loss: 0.0732 - acc: 0.9814 - val_loss: 0.1382 - val_acc: 0.9604\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.97403\n",
      "Epoch 38/40\n",
      "436/436 [==============================] - 6734s 15s/step - loss: 0.0713 - acc: 0.9833 - val_loss: 0.0778 - val_acc: 0.9743\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.97403 to 0.97434, saving model to MyApical4Depth_additionaldepths_only_1to7_withInterleave.h5\n",
      "Epoch 39/40\n",
      "436/436 [==============================] - 6683s 15s/step - loss: 0.0655 - acc: 0.9846 - val_loss: 0.0980 - val_acc: 0.9701\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.97434\n",
      "Epoch 40/40\n",
      "436/436 [==============================] - 6693s 15s/step - loss: 0.0662 - acc: 0.9842 - val_loss: 0.1320 - val_acc: 0.9607\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.97434\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmYFNW5x/Hvyzosyq4oI4uKGwiII+oVV9QLasCIiRLMjSuJEbdoblBMJEZzjYlboteABo1KNF69uOB2FXGLGhlUUCAIsgzDOrLJpjjw3j9ONfQM3TM9Mz3T0z2/z/P0011Vp6rerp55+/SpU6fM3RERkdzSKNMBiIhI+im5i4jkICV3EZEcpOQuIpKDlNxFRHKQkruISA5Scs9hZtbYzDaZWdd0ls0kMzvQzNLef9fMTjWzxXHT88zs+FTKVmNfD5nZjdVdXyQVTTIdgOxiZpviJlsC3wDbo+kfu/ukqmzP3bcDrdNdtiFw94PTsR0zuxS4wN1Pitv2penYtkhFlNzrEXffmVyjmuGl7v56svJm1sTdS+siNpHK6O+xflGzTBYxs1vN7O9m9oSZbQQuMLNjzewDM1tvZivM7I9m1jQq38TM3My6R9OPR8tfNrONZva+mfWoatlo+RAz+9zMNpjZn8zsH2Z2YZK4U4nxx2a2wMzWmdkf49ZtbGZ3m9kaM/sCGFzB8bnJzJ4sN+9+M7sren2pmc2N3s8XUa062baKzeyk6HVLM3ssim02cGSC/S6MtjvbzIZG8w8H7gOOj5q8vow7tuPi1v9J9N7XmNmzZrZPKsemKsc5Fo+ZvW5ma81spZn9Z9x+fhkdk6/MrNDM9k3UBGZm78Y+5+h4vh3tZy1wk5n1NLNp0Xv5MjpubeLW7xa9x5Jo+b1mlhfFfGhcuX3MbIuZdUj2fqUS7q5HPXwAi4FTy827FdgGfIfwxdwCOAo4mvArbH/gc2B0VL4J4ED3aPpx4EugAGgK/B14vBpl9wI2AsOiZT8DvgUuTPJeUonxOaAN0B1YG3vvwGhgNpAPdADeDn+2CfezP7AJaBW37dVAQTT9naiMAacAW4E+0bJTgcVx2yoGTope/wF4E2gHdAPmlCv7fWCf6DP5QRTD3tGyS4E3y8X5ODAuen16FGM/IA/4b+CNVI5NFY9zG2AVcDXQHNgTGBAtuwGYCfSM3kM/oD1wYPljDbwb+5yj91YKXA40Jvw9HgQMAppFfyf/AP4Q934+i45nq6j8cdGyCcBtcfu5Dpic6f/DbH5kPAA9knwwyZP7G5Wsdz3wP9HrRAn7z3FlhwKfVaPsxcA7ccsMWEGS5J5ijMfELf9f4Pro9duE5qnYsjPKJ5xy2/4A+EH0egjweQVlpwBXRK8rSu5F8Z8F8NP4sgm2+xlwZvS6suT+V+C3ccv2JJxnya/s2FTxOP8QKExS7otYvOXmp5LcF1YSw7nA9Oj18cBKoHGCcscBiwCLpj8Bzkn3/1VDeqhZJvssjZ8ws0PM7MXoZ/ZXwC1AxwrWXxn3egsVn0RNVnbf+Dg8/DcWJ9tIijGmtC9gSQXxAvwNGBG9/gGw8yS0mZ1lZv+MmiXWE2rNFR2rmH0qisHMLjSzmVHTwnrgkBS3C+H97dyeu38FrAO6xJVJ6TOr5DjvByxIEsN+hARfHeX/Hjub2VNmtiyK4ZFyMSz2cPK+DHf/B+FXwEAz6w10BV6sZkyC2tyzUflugOMJNcUD3X1P4FeEmnRtWkGoWQJgZkbZZFReTWJcQUgKMZV11fw7cKqZ5ROajf4WxdgCeBr4L0KTSVvg/1KMY2WyGMxsf+ABQtNEh2i7/4rbbmXdNpcTmnpi29uD0PyzLIW4yqvoOC8FDkiyXrJlm6OYWsbN61yuTPn39ztCL6/DoxguLBdDNzNrnCSOR4ELCL8ynnL3b5KUkxQouWe/PYANwObohNSP62CfU4D+ZvYdM2tCaMftVEsxPgVcY2ZdopNrv6iosLuvIjQdPAzMc/f50aLmhHbgEmC7mZ1FaBtONYYbzaythesARscta01IcCWE77lLCTX3mFVAfvyJzXKeAC4xsz5m1pzw5fOOuyf9JVSBio7z80BXMxttZs3MbE8zGxAtewi41cwOsKCfmbUnfKmtJJy4b2xmo4j7Iqoghs3ABjPbj9A0FPM+sAb4rYWT1C3M7Li45Y8RmnF+QEj0UgNK7tnvOuBHhBOc4wk111oVJdDzgLsI/6wHAB8TamzpjvEBYCrwKTCdUPuuzN8Ibeh/i4t5PXAtMJlwUvJcwpdUKm4m/IJYDLxMXOJx91nAH4EPozKHAP+MW/c1YD6wyszim1di679CaD6ZHK3fFRiZYlzlJT3O7r4BOA0YTjiB+zlwYrT498CzhOP8FeHkZl7U3HYZcCPh5PqB5d5bIjcDAwhfMs8Dz8TFUAqcBRxKqMUXET6H2PLFhM95m7u/V8X3LuXETl6IVFv0M3s5cK67v5PpeCR7mdmjhJO04zIdS7bTRUxSLWY2mPAz+2tCV7pSQu1VpFqi8xfDgMMzHUsuULOMVNdAYCHh5/pg4GydAJPqMrP/IvS1/627F2U6nlygZhkRkRykmruISA7KWJt7x44dvXv37pnavYhIVpoxY8aX7l5R12MgheRuZhMJ3ZdWu3vvBMsNuJdwWfgWwqXJH1W23e7du1NYWFhZMRERiWNmlV2lDaTWLPMIFYzERxi/o2f0GEXolywiIhlUaXJ397cJF30kMwx41IMPgLaxIUtFRCQz0nFCtQtlBw8qJsk4I2Y2KhorurCkpCQNuxYRkUTSkdwTDbyUsH+lu09w9wJ3L+jUqdLzASIiUk3pSO7FlB0xL59wKbqIiGRIOpL788B/RKPJHQNscPcVadiuiEhWmTQJuneHRo3C86RJVVueTpUmdzN7gjCGyMEW7it5iYV7Pv4kKvIS4TL0BcCDhLvUiIgkVNsJsKL1a7rvyrY9ahQsWQLu4XnUqF1lKluedpm6BdSRRx7pIlI7Hn/cvVs3d7Pw/PjjVVtek+1XtqxlS/eQ3sKjZctdZSpbnkpcydav6b4rW96tW9llsUe3bqktTxVJbpdY/qHkLlJPZTKBVnf7dZEAK4qtovVruu/KlpslXm6W2vJUKbmL1HP1NYHWZPu1nQAri62i9Wu678qWq+au5C5ZoqZNGzWpXWcygdZk+7WdAGuyvLb3XdtNTjFK7iJe/QSc6fbZmiTQ/farWZKqSYKu7QRYk5p9Oj7TFi3KLs/LS705K5XlqVBylwahstpx+X/GVP+ZM90+W50EmpeXPLG3aJG+L56aJNDKPrPKllelTR7cu3RxHzvW/S9/Cc/HHuverFlY1r69+6OPltl1hftevtz9iCN23/e++7oPG+Z+663ur77qvmaN1yold8kJ1W3amD3bfc89EyeC9u3d585179o1eaJIND/2uP325MtSbfqorHZd0Xu7/373pk13X7d7d/cLLnC/7Tb3a64JSSe2LD/ffd681I9r+S/FFi3cH3ss9fVrWjtN5s9/3pWcY49GjdwPO8z9uOPcjzzSvVcv9x49di/XuHGYP2iQ+1FHhXkFBe4ffFD5fv/+9/B307y5+113uW/c6P7uu+533+3+gx+49+xZdl8nnug+ZYr79u3pe+8xSu6SFWqjXbr8P3V1HsmSc2WPVq3cn3kmefJu3959yJCQaBLt8/vfd1+8ePdj07Wr+y9/6X7++bsSe16e76ydlq+Bxnv9dfeOHcOX3bPPVvx57NgRklKiY5uX537QQe6nnup+ySXu48a5/+lPYd/PPef+5pvuH3/svmiR+9q17t9+G5JbsseOHZX/faxdG2K++mr3vn13fS6x56ZNQ8I+7riQtM84w/2cc0LC/cUv3MePd3/tNfcvvnDftq3s+3z8cfd99gnbuegi91Wrdt//l1+6n3deKHPUUe5z5lQc62uvuf/617s+/1693B9+2P2bbyp/r6lScpd6o7rt2pX9BK8oyd51V6itJlq2777uEybsvu/4Wurpp+9eO87Lc//v/3bfvDnUYsuv37hxSO6xpJMogUNIRtdfH5Jj7NdD+/Zla38DB7o/8EBI9A884H744WF+mzahVv6vf1XtM1iyJNRSwf2GG9xLS3cvM3VqaLYA9/33d//rX90/+sh98mT3e+91v+469+99z33AAPfOnav35Zfoy3CvvcIxOfxw92OOCV8ew4aFJpBYEs/LC8n71ltDjTldyfKrr9x//nP3Jk3Csb333vCl5B6+5Dp3Dst+85td81OxbVv4G4l9bl26uN9xh/v69TWPWcld0mr79uT/UNWtfVe3XRrczz47/ByvaP3qnCArv7yqbcPffus+bVqoaXbqtGu7TZq4Dx3qPmNGxTXWhQtDs8phh5WNq18/9wcfdN+0KdVPbHdbt7pfdlnY3mmnuZeUhPnvved+yilhfn5+qO3G13KT+eYb99Wr3T//3H369PAL4Zln3CdODM0Vt9wSarHJHr/8pfvPfub+4x+H5qSzzw5xHXtsSIonnxzKvf22+9dfV/99p2Lu3PCFDu69e7uPHBleH354+DVSXTt2uL/yyq7ju+ee4cukuLj621RylxorLQ21uVGj3Dt08J010rZtQ03k4INDO2/5JBt/8i5ZAk/W3h2fzCpqXjnwwFC7LV+7TufJu5rascN91iz3zz5LrQmi/Loff+z+u9+5v/9+1devyEMPhbbjbt1CExGE2vM994QvgIZqx47wK6Vbt/A3fcMN6f1SKSwMTTyNGrnfd1/1t5NqcrdQtu4VFBS4brNX/+zYAf/4B/z97/D007BqFbRqBUOHQq9esHkzbNoUnjdvhuefh61bd99Os2bws5/B7bdXPYaWLeHUU2HRIpg9O8QUv9177oHLLw/TkybB2LFQVARdu8Jtt8HIkdV77w1JYSEMHw4bN8J//ieMHg2tW2c6qvph69bwd19bt3hetAj23jv8nVeHmc1w94JKC6byDVAbD9Xc65fly92vvTbUyGNtnMOHu//P/4Q25mQqajpp0iT5shYtwkms2EnB6ta8pfq2bKn4s5X6iRRr7ukY8ldywOjRcN99cOSRoTa8enWouZ97LkyenHwkvK5dE2+vWzdYtw5+8QtoUu427C1awIMPwsSJ8NBDoaxZeJ4woWzNe+RIWLw41N4XL1atPJ1atKh+7VGyQCrfALXxUM29/ti6NfRauPzy3ZfV9iBUIlI1qOYuqXrrrdB+ftZZuy8bOxa2bCk7b8uWMB9CTXrCBNW+ReqbJpUXkVw3ZUr4iX7yybsvKypKvE78/JEjlbBF6hvV3Bs4d3jxxdA7pUWL3Zcna1NPNl9E6gcl9wZu7tzQNStRkwyEroXlT7q1bBnmi0j9peTewE2ZEp7PPDPx8lTa1EWk/lGbewM3ZQr06wdduiQvozZ1keyjmnsDtnZtuBo1WZOMiGQvJfcG7JVXQvdEJXeR3KPk3oC9+CJ06gRHHZXpSEQk3ZTcG6jSUnj55XAitZH+CkRyjv6tG6j33w9jv5x1VhgrJtnYMSKSndRbpoGaMgWaNg0nVa+5ZtcQA0uWwKhR4bV6yIhkL9XcG6gpU+CEE8LFSBWNHSMi2UnJvQFauBDmzAlNMqmMHSMi2UfJvQF68cXwfNZZGjtGJFellNzNbLCZzTOzBWY2JsHybmY21cxmmdmbZpaf/lAlXV58EQ4+GA48UGPHiOSqSpO7mTUG7geGAIcBI8zssHLF/gA86u59gFuA/0p3oJIemzbBtGm7LlzS2DEiuSmV3jIDgAXuvhDAzJ4EhgFz4socBlwbvZ4GPJvOICV9Xn8dtm0re1Wqxo4RyT2pNMt0AZbGTRdH8+LNBIZHr78L7GFmHWoenqTblCnQpg0cd1ymIxGR2pRKcrcE87zc9PXAiWb2MXAisAwo3W1DZqPMrNDMCktKSqocrNTMjh2hvf3f/z30cReR3JVKci8G9oubzgeWxxdw9+Xufo67HwGMjeZtKL8hd5/g7gXuXtCpU6cahC3V8dFHsHKlBgoTaQhSSe7TgZ5m1sPMmgHnA8/HFzCzjmYW29YNwMT0hinpMGVKOGk6ZEimIxGR2lZpcnf3UmA08CowF3jK3Web2S1mNjQqdhIwz8w+B/YG1JGuHnrxRTj2WOjYMdORiEhtS2lsGXd/CXip3Lxfxb1+Gng6vaFJOq1YAYWF8NvfZjoSEakLukK1gYiN9JjsXqkikluU3BuARYvg5pvhjDPg8MMzHY2I1AUl9xznDpdeCk2awPjx4YSqiOQ+jeee4x56CN54IwwpkK8Rf0QaDNXcc9jSpXDddTBoUKi9i0jDoeSeo9zhJz+B7dvDSdQePXQbPZGGRM0yOerxx+Gll+CHP4SbbtJt9EQaGtXcc9DKlXD11WFwsLfe0m30RBoiJfcc4w4//WlI4H/5S2h3T0S30RPJbUruOebpp2HyZLjllnC3Jd1GT6RhUnLPIV9+CVdcAQUF8LOfhXm6jZ5Iw6TkXgVbtoQrPdety3QkiV19NaxfDxMnhouWQLfRE2mo1FumCt58MzR3FBXBww9nOppg3brQtXHiRPj4Y/j1r3cfYkC30RNpeFRzr4LYSchHHglXfabbwoXw/vuwZk3F5XbsCPdCHTEC9tkHrrwS1q6F9u3DLwv1ZRcR1dyroKgoNHd06wY//jHMmgUtWqRn2ytXwoABuxJ7+/Zw0EHh0bNneN5vP/i//wu/GpYsgXbt4LLLoHPnMJSv+rKLSIySexUsXRrGZxk/Hk49NZyUvPXWmm/XHS6/HDZtgsceg5IS+Pzz8HjjDXj00V1lzcK+b78dzj4b8vJCTT1ZX3Yld5GGScm9CoqKQhfCQYPgP/4Dfvc7OP986N27Ztt94gl49ln4/e/hggt2X75lC9x7L9x9967Ev317SOyxuJLFKyINk9rcqyCW3AHuvBPatAnNHzt2VH+bK1eGNvOePeFPf0o8/svkyeEXQklJmI41u8TKqC+7iJSn5J6i7duhuHhXwuzYEe66K5wAHT++etuMDe61cWNo8ikqCvPKJ++xYyseQkB92UWkPCX3FK1cCaWlZWvDP/xhaKIZMwaWL6/6Nv/2N3juOWjdGr7+uuyy+ORdWbOL+rKLSHlK7imKJdL99ts1zwz+/GfYtg2uuqpq21uxIjTH/Nu/Jb8oKrbPVJpdRo6ExYtDE9HixUrsIg2dknuKkiXaAw+EX/0KnnkGnn8++fqTJoW29EaNQs36zDNh69bQrbFbt8TrxPalZhcRqSol9xRVVIu+/vrQY+aKK0L7eXmTJoU29CVLQpt6UVG4mnT48NB/vbLkrWYXEakqJfcUFRWF3jF77rn7sqZN4cEHYdky+PnPdz/5meiEKMA774TnVJK3ml1EpCrUzz1FS5dW3LXwmGNCzf2++8JNqXv3hqOOCo8lS5JvM0bjv4hIOim5pyi+j3sy99wDp50GH34I06eHdviHHkpeXv3QRaS2KLmnqKgo1M4r0rgxDB0aHhDa1xcuDFeWjh8fulLG6ISoiNQmtbmnYPPmMKBXRTXt+N4wsStMzeCAA0JTzSOP6ISoiNQd1dxTEGsbj+/jHi/WG6aiURnVpi4idUk19xRUdjFRZcMDiIjUtZSSu5kNNrN5ZrbAzMYkWN7VzKaZ2cdmNsvMzkh/qJlTWXLXqIwiUt9UmtzNrDFwPzAEOAwYYWaHlSt2E/CUux8BnA/8d7oDzaSiotCWvu++iZdrVEYRqW9SqbkPABa4+0J33wY8CQwrV8aB2OU9bYBqDKNVfy1dGhJ706aJl2t4ABGpb1JJ7l2AuMttKI7mxRsHXGBmxcBLwJWJNmRmo8ys0MwKS2KDk2eByvq4a3gAEalvUknulmCel5seATzi7vnAGcBjZrbbtt19grsXuHtBp06dqh5thqRyAZOGBxCR+iSV5F4MxHcCzGf3ZpdLgKcA3P19IA/omI4AM23HjtAsk6wbpIhIfZRKcp8O9DSzHmbWjHDCtPzgtkXAIAAzO5SQ3LOn3aUCJSXwzTc6OSoi2aXS5O7upcBo4FVgLqFXzGwzu8XMogvtuQ64zMxmAk8AF7p7+aabrFRZN0gRkfoopStU3f0lwonS+Hm/ins9BzguvaHVD0ruIpKNdIVqJZTcRSQbKblXYulSaNUK2rXLdCQiIqlTcq9ErBukJeoQKiJSTym5V6KoSN0gRST7KLlXIpULmERE6hsl9wp8/TWsWrUruSe6IYeISH2km3VUoLg4PHftmtoNOURE6gvV3CsQ3w1SN+QQkWyi5F6B+OSuG3KISDZRcq9A7N6p+fm6IYeIZBcl9woUFcHee0Pz5rohh4hkFyX3CsR3g9QNOUQkm6i3TAWKiqBXr13TI0cqmYtIdlDNPQl3XcAkItlLyT2JtWtDV0cldxHJRkruSWioXxHJZkruSSi5i0g2U3JPItbHXSNCikg2UnJPoqgo9G/v1CnTkYiIVJ2SexKxcdwb6QiJSBZS6kpC3SBFJJspuSeh5C4i2UzJPYFvv4Xly5XcRSR7KbknsGxZuEJVyV1EspWSewLq4y4i2U7JPQH1cReRbKfknkCs5q7kLiLZSsk9gaIi6NABWrXKdCQiItWj5J6AukGKSLZLKbmb2WAzm2dmC8xsTILld5vZJ9HjczNbn/5Q646Su4hku0rvxGRmjYH7gdOAYmC6mT3v7nNiZdz92rjyVwJH1EKsdaaoCE4+OdNRiIhUXyo19wHAAndf6O7bgCeBYRWUHwE8kY7gMmHDBvjqK9XcRSS7pZLcuwBL46aLo3m7MbNuQA/gjSTLR5lZoZkVlpSUVDXWOqGeMiKSC1JJ7pZgnicpez7wtLtvT7TQ3Se4e4G7F3Sqp2Ppxvq4q+YuItksleReDMTXY/OB5UnKnk8WN8mArk4VkdyQSnKfDvQ0sx5m1oyQwJ8vX8jMDgbaAe+nN8S6VVQETZpA586ZjkREpPoqTe7uXgqMBl4F5gJPuftsM7vFzIbGFR0BPOnuyZpsskJREeTnQ+PGmY5ERKT6Ku0KCeDuLwEvlZv3q3LT49IXVuaoj7uI5AJdoVqOkruI5AIl9zjbt0NxsbpBikj2U3KPs2RJSPD775/pSEREakbJPc6caECFQw/NbBwiIjWl5B5n7tzwrOQuItlOyT3O3Lmw997Qvn2mIxERqRkl9zjvvAPr10OjRtC9O0yalOmIRESqJ6V+7g3B44/DggW7ppcsgVGjwuuRIzMTk4hIdanmHhmz2y1IYMsWGDu27mMREakpJffIsmWJ58cGEhMRySZK7pF27RLP19WqIpKNlNwjRx65+7yWLeG22+o+FhGRmlJyj2zfDgccAN26gVl4njBBJ1NFJDupt0xk7lwYPBgefjjTkYiI1Jxq7sC6dbBypa5MFZHcoeSOhh0Qkdyj5M6u5H7YYZmNQ0QkXZTcCcm9efMw5ICISC5Qcick94MP1n1TRSR3KLkTkrva20UklzT45L5lCyxerOQuIrmlwSf3efPAXSdTRSS3NPjkrm6QIpKLlNznhptz9OyZ6UhERNJHyX1uGFOmefNMRyIikj5K7uopIyI5qEEn92+/hfnzldxFJPc06OT+xRchwaunjIjkmgad3NVTRkRyVUrJ3cwGm9k8M1tgZgluJQ1m9n0zm2Nms83sb+kNs3bEkvshh2Q2DhGRdKv0Zh1m1hi4HzgNKAamm9nz7j4nrkxP4AbgOHdfZ2Z71VbA6TR3LuTnwx57ZDoSEZH0SqXmPgBY4O4L3X0b8CQwrFyZy4D73X0dgLuvTm+YtUM9ZUQkV6WS3LsAS+Omi6N58Q4CDjKzf5jZB2Y2ONGGzGyUmRWaWWFJSUn1Ik6THTtCctfJVBHJRakkd0swz8tNNwF6AicBI4CHzKztbiu5T3D3Ancv6NSpU1VjrbFJk8KY7Y0aQdeuYdAw1dxFJBelcoPsYmC/uOl8YHmCMh+4+7fAIjObR0j209MSZRpMmgSjRoWEDrBsWXguLs5cTCIitSWVmvt0oKeZ9TCzZsD5wPPlyjwLnAxgZh0JzTQL0xloTY0duyuxx3vkkToPRUSk1lWa3N29FBgNvArMBZ5y99lmdouZDY2KvQqsMbM5wDTg5+6+praCro6iosTzYzV4EZFcYu7lm8/rRkFBgRcWFtbZ/rp3hyVLdp/frVu4WYeISDYwsxnuXlBZuQZzheptt0HLlmXnNWkS5ouI5JoGk9xHjoQJE0JNPeb888N8EZFc02CSO4REvngxvPlmmL7ggkxGIyJSe3Iuua9fD0uXVlxGA4aJSK7LqeS+cSP827+Fq07ffz95ublzoVUr2G+/5GVERLJZziR3d7joIpg3D9q1gyFD4KOPEpeNjSljia69FRHJATmT3H//e3jmGfjd7+Ddd6FtWzjtNPj0093LzpmjJhkRyW05kdynToUbboDvfQ+uuy6MG/PGG9CiBZx6KvzrX7vKfvVVuHBJyV1EclnWJ/clS+C888INNyZO3NXUsv/+IembwaBB4ZZ6sCvRK7mLSC7L6uT+9dcwfHi4D+r//i+0bl12+cEHw+uvwzffwCmnhC8C9ZQRkYYga5O7O/z0pzBjBjz6aEjkifTuDa+9FppjBg0KtfmmTeGAA+o2XhGRupS1yX3CBHj4YbjpJhgW3Rcqfrz27t3DNMARR8Arr8Dq1fDYY3DQQWHoARGRXJWVyf2DD+DKK+Hf/x3GjQvzYuO1L1kSavVLloTpWII/+mh48cUwvkyfPhkLXUSkTmTdqJCrVsGRR0KzZlBYCO3bh/mpjvq4YAG0aQMZuBGUiEiNpToqZNY1Ttx/P6xZE65AjSV2SD5ee/n5Bx5Ye7GJiNQXWdcsM25caJbp16/s/K5dE5dPNl9EJJdlXXJv1Aj69t19fqLx2lu21HjtItIwZV2zTDKxcdnHjg1NMV27hsSu8dpFyvr2228pLi7m66+/znQoUoG8vDzy8/Np2rRptdbPuhOqIlIzixYtYo899qBDhw6YRs+rl9ydNWvWsHHjRnr06FFmmW6zJyIJff3110rs9ZyZ0aFDhxr9ulJyF2mAlNjrv5p+RkruIiI5SMldRCqUbFiP6lqzZg39+vWjX79+dO7cmS5duuyc3rZtW0rbuOiii5gmRtT5AAAOk0lEQVQ3b16FZe6//34m1TTYLJYzvWVEJP1iw3ps2RKmY8N6QPV7onXo0IFPPvkEgHHjxtG6dWuuv/76MmXcHXenUaPE9c+HH3640v1cccUV1QswR6jmLiJJjR27K7HHbNkS5qfbggUL6N27Nz/5yU/o378/K1asYNSoURQUFNCrVy9uueWWnWUHDhzIJ598QmlpKW3btmXMmDH07duXY489ltWrVwNw0003cc899+wsP2bMGAYMGMDBBx/Me++9B8DmzZsZPnw4ffv2ZcSIERQUFOz84ol38803c9RRR+2ML9bL8PPPP+eUU06hb9++9O/fn8XRWCe//e1vOfzww+nbty9ja+NgpUDJXUSSSnVYj3SZM2cOl1xyCR9//DFdunTh9ttvp7CwkJkzZ/Laa68xZ86c3dbZsGEDJ554IjNnzuTYY49l4sSJCbft7nz44Yf8/ve/3/lF8ac//YnOnTszc+ZMxowZw8cff5xw3auvvprp06fz6aefsmHDBl555RUARowYwbXXXsvMmTN577332GuvvXjhhRd4+eWX+fDDD5k5cybXXXddmo5O1Si5i0hSdT2sxwEHHMBRRx21c/qJJ56gf//+9O/fn7lz5yZM7i1atGDIkCEAHHnkkTtrz+Wdc845u5V59913Of/88wHo27cvvXr1Srju1KlTGTBgAH379uWtt95i9uzZrFu3ji+//JLvfOc7QLjoqGXLlrz++utcfPHFtGjRAoD28YNg1SEldxFJqq6H9WjVqtXO1/Pnz+fee+/ljTfeYNasWQwePDhhv+9mzZrtfN24cWNKS0sTbrt58+a7lUnlIs4tW7YwevRoJk+ezKxZs7j44ot3xpGou6K714uupkruIpLUyJHhxjjduoX7EXfrFqbrYliPr776ij322IM999yTFStW8Oqrr6Z9HwMHDuSpp54C4NNPP034y2Dr1q00atSIjh07snHjRp555hkA2rVrR8eOHXnhhReAcHHYli1bOP300/nLX/7C1q1bAVi7dm3a405FSsndzAab2TwzW2BmYxIsv9DMSszsk+hxafpDFZFMGDky3BNhx47wXFfjNfXv35/DDjuM3r17c9lll3HcccelfR9XXnkly5Yto0+fPtx555307t2bNm3alCnToUMHfvSjH9G7d2+++93vcvTRR+9cNmnSJO6880769OnDwIEDKSkp4ayzzmLw4MEUFBTQr18/7r777rTHnYpKx5Yxs8bA58BpQDEwHRjh7nPiylwIFLj76FR3rLFlRDJj7ty5HKo7xANQWlpKaWkpeXl5zJ8/n9NPP5358+fTpJ7chzPRZ5XOm3UMABa4+8Jow08Cw4Ddf7+IiGSRTZs2MWjQIEpLS3F3xo8fX28Se02l8i66AEvjpouBoxOUG25mJxBq+de6+9IEZURE6o22bdsyY8aMTIdRK1Jpc0902rd8W84LQHd37wO8Dvw14YbMRplZoZkVlpSUVC1SERFJWSrJvRjYL246H1geX8Dd17j7N9Hkg8CRiTbk7hPcvcDdCzrpDtUiIrUmleQ+HehpZj3MrBlwPvB8fAEz2yducigwN30hiohIVVXa5u7upWY2GngVaAxMdPfZZnYLUOjuzwNXmdlQoBRYC1xYizGLiEglUurn7u4vuftB7n6Au98WzftVlNhx9xvcvZe793X3k939X7UZtIhkr5NOOmm3C5LuuecefvrTn1a4XuvWrQFYvnw55557btJtV9bF+p577mFL3GhoZ5xxBuvXr08l9KyiK1RFpE6NGDGCJ598ssy8J598khEjRqS0/r777svTTz9d7f2XT+4vvfQSbdu2rfb26qvc6NApItVyzTWQYITbGunXD6KRdhM699xzuemmm/jmm29o3rw5ixcvZvny5QwcOJBNmzYxbNgw1q1bx7fffsutt97KsGHDyqy/ePFizjrrLD777DO2bt3KRRddxJw5czj00EN3XvIPcPnllzN9+nS2bt3Kueeey69//Wv++Mc/snz5ck4++WQ6duzItGnT6N69O4WFhXTs2JG77rpr56iSl156Kddccw2LFy9myJAhDBw4kPfee48uXbrw3HPP7RwYLOaFF17g1ltvZdu2bXTo0IFJkyax9957s2nTJq688koKCwsxM26++WaGDx/OK6+8wo033sj27dvp2LEjU6dOTd+HgJK7iNSxDh06MGDAAF555RWGDRvGk08+yXnnnYeZkZeXx+TJk9lzzz358ssvOeaYYxg6dGjSgbgeeOABWrZsyaxZs5g1axb9+/ffuey2226jffv2bN++nUGDBjFr1iyuuuoq7rrrLqZNm0bHjh3LbGvGjBk8/PDD/POf/8TdOfrooznxxBNp164d8+fP54knnuDBBx/k+9//Ps888wwXXHBBmfUHDhzIBx98gJnx0EMPcccdd3DnnXfym9/8hjZt2vDpp58CsG7dOkpKSrjssst4++236dGjR62MP6PkLtKAVVTDrk2xpplYco/Vlt2dG2+8kbfffptGjRqxbNkyVq1aRefOnRNu5+233+aqq64CoE+fPvTp02fnsqeeeooJEyZQWlrKihUrmDNnTpnl5b377rt897vf3Tky5TnnnMM777zD0KFD6dGjB/369QOSDytcXFzMeeedx4oVK9i2bRs9evQA4PXXXy/TDNWuXTteeOEFTjjhhJ1lamNY4Kxqc0/3vRxFJDPOPvtspk6dykcffcTWrVt31rgnTZpESUkJM2bM4JNPPmHvvfdOOMxvvES1+kWLFvGHP/yBqVOnMmvWLM4888xKt1PROFux4YIh+bDCV155JaNHj+bTTz9l/PjxO/eXaAjguhgWOGuSe+xejkuWgPuuezkqwYtkn9atW3PSSSdx8cUXlzmRumHDBvbaay+aNm3KtGnTWLJkSYXbOeGEE3beBPuzzz5j1qxZQBguuFWrVrRp04ZVq1bx8ssv71xnjz32YOPGjQm39eyzz7JlyxY2b97M5MmTOf7441N+Txs2bKBLly4A/PWvuy7SP/3007nvvvt2Tq9bt45jjz2Wt956i0WLFgG1Myxw1iT3uryXo4jUvhEjRjBz5sydd0ICGDlyJIWFhRQUFDBp0iQOOeSQCrdx+eWXs2nTJvr06cMdd9zBgAEDgHBXpSOOOIJevXpx8cUXlxkueNSoUQwZMoSTTz65zLb69+/PhRdeyIABAzj66KO59NJLOeKII1J+P+PGjeN73/sexx9/fJn2/Jtuuol169bRu3dv+vbty7Rp0+jUqRMTJkzgnHPOoW/fvpx33nkp7ydVlQ75W1uqOuRvo0ahxl6eWRhnWkRSoyF/s0dNhvzNmpp7Xd/LUUQkm2VNcq/rezmKiGSzrEnumbyXo0iuyVRzrKSupp9RVvVzHzlSyVykpvLy8lizZg0dOnSo9e54Uj3uzpo1a8jLy6v2NrIquYtIzeXn51NcXIxumFO/5eXlkZ+fX+31ldxFGpimTZvuvDJSclfWtLmLiEjqlNxFRHKQkruISA7K2BWqZlYCVDxwRHIdgS/TGE46KbbqUWzVo9iqJ5tj6+bunSrbSMaSe02YWWEql99mgmKrHsVWPYqtehpCbGqWERHJQUruIiI5KFuT+4RMB1ABxVY9iq16FFv15HxsWdnmLiIiFcvWmruIiFRAyV1EJAdlXXI3s8FmNs/MFpjZmEzHE8/MFpvZp2b2iZmlfpup2ollopmtNrPP4ua1N7PXzGx+9NyuHsU2zsyWRcfuEzM7I0Ox7Wdm08xsrpnNNrOro/kZP3YVxJbxY2dmeWb2oZnNjGL7dTS/h5n9MzpufzezZvUotkfMbFHccetX17HFxdjYzD42synRdM2Pm7tnzQNoDHwB7A80A2YCh2U6rrj4FgMdMx1HFMsJQH/gs7h5dwBjotdjgN/Vo9jGAdfXg+O2D9A/er0H8DlwWH04dhXElvFjBxjQOnrdFPgncAzwFHB+NP/PwOX1KLZHgHMz/TcXxfUz4G/AlGi6xsct22ruA4AF7r7Q3bcBTwLDMhxTveTubwPlb6k+DIjdlv2vwNl1GlQkSWz1gruvcPePotcbgblAF+rBsasgtozzYFM02TR6OHAK8HQ0P1PHLVls9YKZ5QNnAg9F00Yajlu2JfcuwNK46WLqyR93xIH/M7MZZjYq08EksLe7r4CQKIC9MhxPeaPNbFbUbJORJqN4ZtYdOIJQ06tXx65cbFAPjl3UtPAJsBp4jfAre727l0ZFMvb/Wj42d48dt9ui43a3mTXPRGzAPcB/Ajui6Q6k4bhlW3JPdNuYevMNDBzn7v2BIcAVZnZCpgPKIg8ABwD9gBXAnZkMxsxaA88A17j7V5mMpbwEsdWLY+fu2929H5BP+JV9aKJidRtVtNNysZlZb+AG4BDgKKA98Iu6jsvMzgJWu/uM+NkJilb5uGVbci8G9oubzgeWZyiW3bj78uh5NTCZ8Aden6wys30AoufVGY5nJ3dfFf0D7gAeJIPHzsyaEpLnJHf/32h2vTh2iWKrT8cuimc98CahXbutmcVuCpTx/9e42AZHzVzu7t8AD5OZ43YcMNTMFhOamU8h1ORrfNyyLblPB3pGZ5KbAecDz2c4JgDMrJWZ7RF7DZwOfFbxWnXueeBH0esfAc9lMJYyYokz8l0ydOyi9s6/AHPd/a64RRk/dsliqw/Hzsw6mVnb6HUL4FTCOYFpwLlRsUwdt0Sx/Svuy9oIbdp1ftzc/QZ3z3f37oR89oa7jyQdxy3TZ4mrcVb5DEIvgS+AsZmOJy6u/Qm9d2YCszMdG/AE4Sf6t4RfPJcQ2vKmAvOj5/b1KLbHgE+BWYREuk+GYhtI+Ak8C/gkepxRH45dBbFl/NgBfYCPoxg+A34Vzd8f+BBYAPwP0LwexfZGdNw+Ax4n6lGTqQdwErt6y9T4uGn4ARGRHJRtzTIiIpICJXcRkRyk5C4ikoOU3EVEcpCSu4hIDlJyFxHJQUruIiI56P8BTkrWJ8rIZhoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3312, 7)\n",
      "[[1.03481834e-05 2.56494855e-06 1.12755260e-04 ... 2.78107793e-04\n",
      "  9.99124110e-01 4.46532824e-04]\n",
      " [9.87619296e-06 2.40976306e-06 1.09835782e-04 ... 2.92550074e-04\n",
      "  9.99151111e-01 4.08658409e-04]\n",
      " [1.04254359e-05 2.59287231e-06 1.15321011e-04 ... 2.94490659e-04\n",
      "  9.99125898e-01 4.25061386e-04]\n",
      " ...\n",
      " [1.12946481e-07 1.39754883e-08 5.94693447e-05 ... 9.89692271e-01\n",
      "  1.01503534e-02 1.07236275e-10]\n",
      " [1.45183435e-07 1.81871620e-08 7.05369457e-05 ... 9.86692131e-01\n",
      "  1.31255286e-02 1.71146278e-10]\n",
      " [8.40437133e-06 1.40700092e-06 5.88619616e-04 ... 1.21611856e-01\n",
      "  8.77425194e-01 1.87506134e-06]]\n"
     ]
    }
   ],
   "source": [
    "train_datagen_top = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    height_shift_range=0.05, #0.2, #\n",
    "    width_shift_range=0.05, #0.2, #\n",
    "    rotation_range=15, #40, #15,\n",
    "    shear_range=0.2,\n",
    "    brightness_range=[0.5,1.5],\n",
    "    zoom_range=[0.9,1.25],\n",
    "    rescale=1/255.0)\n",
    "\n",
    "# train generator\n",
    "train_generator_top = train_datagen_top.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    shuffle=True)\n",
    "\n",
    "\n",
    "nb_train_samples = len(train_generator_top.filenames)\n",
    "num_classes = len(train_generator_top.class_indices)\n",
    "\n",
    "train_labels = train_generator_top.classes\n",
    "train_labels = to_categorical(train_labels, num_classes= num_classes)\n",
    "\n",
    "#validation generator\n",
    "valid_datagen_top = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "valid_generator_top = valid_datagen_top.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical', \n",
    "    shuffle=False) #True\n",
    "\n",
    "nb_validation_samples = len(valid_generator_top.filenames)\n",
    "validation_labels = valid_generator_top.classes\n",
    "validation_labels = to_categorical(\n",
    "    validation_labels, num_classes=num_classes)\n",
    "\n",
    "\n",
    "print(len(train_generator_top.class_indices))\n",
    "print(train_labels)\n",
    "print(validation_labels)\n",
    "\n",
    "# crop\n",
    "#train_generator_crops = crop_generator(train_generator_top, crop_size)\n",
    "#validation_generator_crops = crop_generator(valid_generator_top, crop_size)\n",
    "\n",
    "\n",
    "#######\n",
    "base_model = load_model(base_model_path)\n",
    "#base_model.layers.pop()\n",
    "#base_model.outputs = [base_model.layers[-1].output]\n",
    "#base_model.layers[-1].outbound_nodes = []\n",
    "#base_model.summary()\n",
    "base_model.built = False \n",
    "\n",
    "input_shape = (256,256,1)\n",
    "model_input = Input(shape = input_shape)\n",
    "model_input = Lambda(mean_subtract, name='mean_subtraction')(model_input)\n",
    "base_model.Input = model_input\n",
    "\n",
    "\n",
    "#########\n",
    "## dense model\n",
    "model = Sequential()\n",
    "model.add(base_model) # add base model\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(256, activation='relu'))\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dense(128, kernel_regularizer=regularizers.l2(0.001),activation='relu'))\n",
    "#model.add(Dense(64, kernel_regularizer=regularizers.l2(0.001),activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Dense(16, kernel_regularizer=regularizers.l2(0.001),activation='relu'))\n",
    "#model.add(Dropout(0.4))\n",
    "#model.add(Dense(64, activation='relu')) # new\n",
    "#model.add(Dropout(0.5)) #new\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary() \n",
    "\n",
    "\n",
    "\n",
    "print(\"[INFO] compile...\")\n",
    "#model.compile(optimizer='rmsprop',\n",
    "#            loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#sgd = optimizers.SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "mydecay = 0.0005\n",
    "mymomentum = 0.9\n",
    "mylr = 0.01 #0.009 #0.01 #0.03 #0.001 #0.1 #0.01\n",
    "sgd = optimizers.SGD(lr=mylr, decay=mydecay, momentum=mymomentum)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"[INFO] model fit...\")\n",
    "#history = model.fit_generator(train_generator_crops,\n",
    "#                    steps_per_epoch= nb_train_samples//batch_size, #100, #50,  #1000,\n",
    "#                    epochs= nepochs,\n",
    "#                    validation_data= validation_generator_crops,\n",
    "#                    validation_steps= nb_validation_samples//batch_size, #50, #8, #50, # 800,\n",
    "#                    verbose=1)\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint('MyApical4Depth_additionaldepths_only_1to7_withInterleave.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator_top,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=nepochs,\n",
    "    validation_data= valid_generator_top,\n",
    "    validation_steps=nb_validation_samples//batch_size,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1)\n",
    "\n",
    "#history = model.fit_generator(train_generator_top,\n",
    "#                steps_per_epoch= nb_train_samples//batch_size, #100, #50,  #1000,\n",
    "#                epochs= nepochs,\n",
    "#                validation_data= valid_generator_top,\n",
    "#                validation_steps= nb_validation_samples//batch_size, #50, #8, #50, # 800,\n",
    "#                verbose=1)\n",
    "#\n",
    "\n",
    "#base_model.save_weights(top_model_weights_path)\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "predictions= model.predict_generator(valid_generator_top, steps = nb_validation_samples // batch_size)\n",
    "y_classes = predictions.argmax(axis=-1)\n",
    "print(predictions.shape)\n",
    "print (predictions)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3344 images belonging to 7 classes.\n",
      "3344/3344 [==============================] - 408s 122ms/step\n",
      "3344\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "model.evaluate_generator(generator=valid_generator_top, steps = nb_validation_samples // batch_size)\n",
    "\n",
    "\n",
    "# create test generator with valid directory ( due to lack of data)\n",
    "valid_generator = valid_datagen_top.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=1,\n",
    "    color_mode='grayscale',\n",
    "    class_mode=None, \n",
    "    shuffle=False,\n",
    "    seed=42) \n",
    "\n",
    "valid_generator.reset()\n",
    "pred=model.predict_generator(valid_generator,steps = len(valid_generator), verbose=1)\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "\n",
    "labels = (train_generator_top.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "#predictions= model.predict_generator(valid_generator_top, steps = nb_validation_samples // batch_size)\n",
    "#y_classes = predictions.argmax(axis=-1)\n",
    "#print(predictions.shape)\n",
    "#print (predictions)\n",
    "\n",
    "print(len(predictions))\n",
    "\n",
    "filenames=valid_generator.filenames\n",
    "#print(filenames.shape)\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.to_csv(\"results_validation.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion MatrixPredict...\n",
      "3344/3344 [==============================] - 397s 119ms/step\n",
      "Confusion Matrix\n",
      "[[487  13   0   0   0   0   0]\n",
      " [  0 401  44   0   0   0   0]\n",
      " [  0   3 469  39   0   0   0]\n",
      " [  0   0  14 471  11   0   0]\n",
      " [  0   0   0   0 462   2   0]\n",
      " [  0   0   0   0   0 462   2]\n",
      " [  0   0   0   0   0   2 462]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Depth1       1.00      0.97      0.99       500\n",
      "      Depth2       0.96      0.90      0.93       445\n",
      "      Depth3       0.89      0.92      0.90       511\n",
      "      Depth4       0.92      0.95      0.94       496\n",
      "      Depth5       0.98      1.00      0.99       464\n",
      "      Depth6       0.99      1.00      0.99       464\n",
      "      Depth7       1.00      1.00      1.00       464\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      3344\n",
      "   macro avg       0.96      0.96      0.96      3344\n",
      "weighted avg       0.96      0.96      0.96      3344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print (predictions)\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "#confusion_matrix(valid_generator_top.classes, y_classes)\n",
    "print('Confusion MatrixPredict...')\n",
    "valid_generator.reset()\n",
    "predCM=model.predict_generator(valid_generator,steps = len(valid_generator),verbose=1)\n",
    "y_pred = predCM.argmax(axis=-1) #np.argmax(predictions, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(valid_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['Depth1', 'Depth2', 'Depth3', 'Depth4', 'Depth5','Depth6','Depth7' ]\n",
    "print(classification_report(valid_generator.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1658 images belonging to 7 classes.\n",
      "test acc: 0.9693627450980392\n",
      "Found 1658 images belonging to 7 classes.\n",
      "1658/1658 [==============================] - 197s 119ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_data_dir ='Apical4_AdditionalDepths_Only_1to7_WithInterleave/Test'\n",
    "\n",
    "test_datagen_top = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_generator_top = test_datagen_top.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical', \n",
    "    shuffle=False) #True\n",
    "\n",
    "nb_test_samples = len(test_generator_top.filenames)\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(generator=test_generator_top, steps = nb_test_samples//batch_size)\n",
    "\n",
    "print('test acc:', test_acc)\n",
    "\n",
    "# create test generator with actual test data\n",
    "test_generator = test_datagen_top.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=1,\n",
    "    color_mode='grayscale',\n",
    "    class_mode=None, \n",
    "    shuffle=False,\n",
    "    seed=42) \n",
    "\n",
    "\n",
    "\n",
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator, steps = len(test_generator), verbose=1)\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "\n",
    "labels = (train_generator_top.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "#predictions= model.predict_generator(valid_generator_top, steps = nb_validation_samples // batch_size)\n",
    "#y_classes = predictions.argmax(axis=-1)\n",
    "#print(predictions.shape)\n",
    "#print (predictions)\n",
    "\n",
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.to_csv(\"results_forTestdata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion MatrixPredict...\n",
      "1658/1658 [==============================] - 198s 119ms/step\n",
      "Confusion Matrix\n",
      "[[235  12   0   0   0   0   0]\n",
      " [  0 199  16   0   0   0   0]\n",
      " [  0   0 209  20   0   0   0]\n",
      " [  0   0   1 239   1   0   0]\n",
      " [  0   0   0   0 242   0   0]\n",
      " [  0   0   0   0   0 242   0]\n",
      " [  0   0   0   0   0   0 242]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Depth1       1.00      0.95      0.98       247\n",
      "      Depth2       0.94      0.93      0.93       215\n",
      "      Depth3       0.92      0.91      0.92       229\n",
      "      Depth4       0.92      0.99      0.96       241\n",
      "      Depth5       1.00      1.00      1.00       242\n",
      "      Depth6       1.00      1.00      1.00       242\n",
      "      Depth7       1.00      1.00      1.00       242\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1658\n",
      "   macro avg       0.97      0.97      0.97      1658\n",
      "weighted avg       0.97      0.97      0.97      1658\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print (predictions)\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "#confusion_matrix(valid_generator_top.classes, y_classes)\n",
    "print('Confusion MatrixPredict...')\n",
    "test_generator.reset()\n",
    "predCM=model.predict_generator(test_generator,steps = len(test_generator), verbose=1)\n",
    "y_pred = predCM.argmax(axis=-1) #np.argmax(predictions, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['Depth1', 'Depth2', 'Depth3', 'Depth4', 'Depth5','Depth6','Depth7']\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=target_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint ( type(predCM))\\nprint (predCM.shape)\\nprint(predCM > 0.9)\\nthresval = (predCM > 0.9).astype(int).sum(axis=1)\\nprint(thresval.shape)\\nprint(thresval)\\nsumthresval_d12 = predCM[:,0]+predCM[:,1]\\nsumthresval_d23 = predCM[:,1]+predCM[:,2]\\nsumthresval_d34 = predCM[:,2]+predCM[:,3]\\nsumthresval = np.stack((sumthresval_d12,sumthresval_d23,sumthresval_d34),axis=1)\\nprint(sumthresval.shape)\\npredictions = []\\nfor i,v in enumerate(thresval):\\n    if v==0:\\n        if sumthresval[i,:].max()>0.9:\\n            print(np.argmax(sumthresval[i,:])+0.5)\\n            predictions.append(np.argmax(sumthresval[i,:])+0.5)\\n        else:\\n            print(\\'fail\\')\\n            predictions.append(-1)\\n    else:\\n        print(np.argmax(predCM[i,:]))\\n        predictions.append(np.argmax(predCM[i,:]))    \\n\\nlabelsval = {-1:\\'f\\',0:\\'1\\',0.5:\\'1.5\\',1.0:\\'2\\',1.5:\\'2.5\\',2.0:\\'3\\',2.5:\\'3.5\\',3.0:\\'4\\'}\\npredictions = [labelsval[k] for k in predictions]\\n\\nfilenames=test_generator.filenames\\nresults=pd.DataFrame({\"Filename\":filenames,\\n                      \"Predictions\":predictions})\\nresults.to_csv(\"results_forTestdata_WithThresholdVal.csv\",index=False)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "print ( type(predCM))\n",
    "print (predCM.shape)\n",
    "print(predCM > 0.9)\n",
    "thresval = (predCM > 0.9).astype(int).sum(axis=1)\n",
    "print(thresval.shape)\n",
    "print(thresval)\n",
    "sumthresval_d12 = predCM[:,0]+predCM[:,1]\n",
    "sumthresval_d23 = predCM[:,1]+predCM[:,2]\n",
    "sumthresval_d34 = predCM[:,2]+predCM[:,3]\n",
    "sumthresval = np.stack((sumthresval_d12,sumthresval_d23,sumthresval_d34),axis=1)\n",
    "print(sumthresval.shape)\n",
    "predictions = []\n",
    "for i,v in enumerate(thresval):\n",
    "    if v==0:\n",
    "        if sumthresval[i,:].max()>0.9:\n",
    "            print(np.argmax(sumthresval[i,:])+0.5)\n",
    "            predictions.append(np.argmax(sumthresval[i,:])+0.5)\n",
    "        else:\n",
    "            print('fail')\n",
    "            predictions.append(-1)\n",
    "    else:\n",
    "        print(np.argmax(predCM[i,:]))\n",
    "        predictions.append(np.argmax(predCM[i,:]))    \n",
    "\n",
    "labelsval = {-1:'f',0:'1',0.5:'1.5',1.0:'2',1.5:'2.5',2.0:'3',2.5:'3.5',3.0:'4'}\n",
    "predictions = [labelsval[k] for k in predictions]\n",
    "\n",
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.to_csv(\"results_forTestdata_WithThresholdVal.csv\",index=False)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pandas as pd\\n\\ntest_data_dir2 =\\'Apical4_AdditionalDepths_1to8/Test_2\\'\\n\\ntest_datagen_top2 = ImageDataGenerator(rescale=1. / 255)\\n\\ntest_generator_top2 = test_datagen_top2.flow_from_directory(\\n    test_data_dir2,\\n    target_size=(img_width, img_height),\\n    batch_size=batch_size,\\n    color_mode=\\'grayscale\\',\\n    class_mode=\\'categorical\\', \\n    shuffle=False) #True\\n\\ntest_loss2, test_acc2 = model.evaluate_generator(generator=test_generator_top2)\\n\\nprint(\\'test acc_2:\\', test_acc2)\\n\\n# create test generator with actual test data\\ntest_generator2 = test_datagen_top2.flow_from_directory(\\n    test_data_dir2,\\n    target_size=(img_width, img_height),\\n    batch_size=1,\\n    color_mode=\\'grayscale\\',\\n    class_mode=None, \\n    shuffle=False,\\n    seed=42) \\n\\n\\n\\ntest_generator2.reset()\\npred2=model.predict_generator(test_generator2,verbose=1)\\npredicted_class_indices=np.argmax(pred2,axis=1)\\n\\nlabels = (train_generator_top.class_indices)\\nlabels = dict((v,k) for k,v in labels.items())\\npredictions = [labels[k] for k in predicted_class_indices]\\n\\n#predictions= model.predict_generator(valid_generator_top, steps = nb_validation_samples // batch_size)\\n#y_classes = predictions.argmax(axis=-1)\\n#print(predictions.shape)\\n#print (predictions)\\n\\nfilenames=test_generator2.filenames\\nresults=pd.DataFrame({\"Filename\":filenames,\\n                      \"Predictions\":predictions})\\nresults.to_csv(\"results_forTestdata_2.csv\",index=False)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "test_data_dir2 ='Apical4_AdditionalDepths_1to8/Test_2'\n",
    "\n",
    "test_datagen_top2 = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_generator_top2 = test_datagen_top2.flow_from_directory(\n",
    "    test_data_dir2,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical', \n",
    "    shuffle=False) #True\n",
    "\n",
    "test_loss2, test_acc2 = model.evaluate_generator(generator=test_generator_top2)\n",
    "\n",
    "print('test acc_2:', test_acc2)\n",
    "\n",
    "# create test generator with actual test data\n",
    "test_generator2 = test_datagen_top2.flow_from_directory(\n",
    "    test_data_dir2,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=1,\n",
    "    color_mode='grayscale',\n",
    "    class_mode=None, \n",
    "    shuffle=False,\n",
    "    seed=42) \n",
    "\n",
    "\n",
    "\n",
    "test_generator2.reset()\n",
    "pred2=model.predict_generator(test_generator2,verbose=1)\n",
    "predicted_class_indices=np.argmax(pred2,axis=1)\n",
    "\n",
    "labels = (train_generator_top.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "#predictions= model.predict_generator(valid_generator_top, steps = nb_validation_samples // batch_size)\n",
    "#y_classes = predictions.argmax(axis=-1)\n",
    "#print(predictions.shape)\n",
    "#print (predictions)\n",
    "\n",
    "filenames=test_generator2.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.to_csv(\"results_forTestdata_2.csv\",index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#print (predictions)\\nimport sklearn as sk\\nfrom sklearn.metrics import confusion_matrix\\nfrom sklearn.metrics import classification_report\\nimport numpy as np\\n\\n#confusion_matrix(valid_generator_top.classes, y_classes)\\nprint('Confusion MatrixPredict...')\\ntest_generator2.reset()\\npredCM=model.predict_generator(test_generator2,verbose=1)\\ny_pred2 = predCM.argmax(axis=-1) #np.argmax(predictions, axis=1)\\nprint('Confusion Matrix')\\nprint(confusion_matrix(test_generator2.classes, y_pred2))\\nprint('Classification Report')\\ntarget_names = ['Depth1', 'Depth2', 'Depth3', 'Depth4']\\nprint(classification_report(test_generator2.classes, y_pred2, target_names=target_names))\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#print (predictions)\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "#confusion_matrix(valid_generator_top.classes, y_classes)\n",
    "print('Confusion MatrixPredict...')\n",
    "test_generator2.reset()\n",
    "predCM=model.predict_generator(test_generator2,verbose=1)\n",
    "y_pred2 = predCM.argmax(axis=-1) #np.argmax(predictions, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator2.classes, y_pred2))\n",
    "print('Classification Report')\n",
    "target_names = ['Depth1', 'Depth2', 'Depth3', 'Depth4']\n",
    "print(classification_report(test_generator2.classes, y_pred2, target_names=target_names))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pandas as pd\\n\\ntest_data_dir3 =\\'NewDataSetUsingValveDetection_NODuplicates_RANGE_VER5/Test_3\\'\\n\\ntest_datagen_top3 = ImageDataGenerator(rescale=1. / 255)\\n\\ntest_generator_top3 = test_datagen_top3.flow_from_directory(\\n    test_data_dir3,\\n    target_size=(img_width, img_height),\\n    batch_size=batch_size,\\n    color_mode=\\'grayscale\\',\\n    class_mode=\\'categorical\\', \\n    shuffle=False) #True\\n\\ntest_loss3, test_acc3 = model.evaluate_generator(generator=test_generator_top3)\\n\\nprint(\\'test acc_3:\\', test_acc3)\\n\\n# create test generator with actual test data\\ntest_generator3 = test_datagen_top3.flow_from_directory(\\n    test_data_dir3,\\n    target_size=(img_width, img_height),\\n    batch_size=1,\\n    color_mode=\\'grayscale\\',\\n    class_mode=None, \\n    shuffle=False,\\n    seed=42) \\n\\n\\n\\ntest_generator3.reset()\\npred3=model.predict_generator(test_generator3,verbose=1)\\npredicted_class_indices=np.argmax(pred3,axis=1)\\n\\nlabels = (train_generator_top.class_indices)\\nlabels = dict((v,k) for k,v in labels.items())\\npredictions = [labels[k] for k in predicted_class_indices]\\n\\n#predictions= model.predict_generator(valid_generator_top, steps = nb_validation_samples // batch_size)\\n#y_classes = predictions.argmax(axis=-1)\\n#print(predictions.shape)\\n#print (predictions)\\n\\nfilenames=test_generator3.filenames\\nresults=pd.DataFrame({\"Filename\":filenames,\\n                      \"Predictions\":predictions})\\nresults.to_csv(\"results_forTestdata_3.csv\",index=False)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "test_data_dir3 ='NewDataSetUsingValveDetection_NODuplicates_RANGE_VER5/Test_3'\n",
    "\n",
    "test_datagen_top3 = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_generator_top3 = test_datagen_top3.flow_from_directory(\n",
    "    test_data_dir3,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical', \n",
    "    shuffle=False) #True\n",
    "\n",
    "test_loss3, test_acc3 = model.evaluate_generator(generator=test_generator_top3)\n",
    "\n",
    "print('test acc_3:', test_acc3)\n",
    "\n",
    "# create test generator with actual test data\n",
    "test_generator3 = test_datagen_top3.flow_from_directory(\n",
    "    test_data_dir3,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=1,\n",
    "    color_mode='grayscale',\n",
    "    class_mode=None, \n",
    "    shuffle=False,\n",
    "    seed=42) \n",
    "\n",
    "\n",
    "\n",
    "test_generator3.reset()\n",
    "pred3=model.predict_generator(test_generator3,verbose=1)\n",
    "predicted_class_indices=np.argmax(pred3,axis=1)\n",
    "\n",
    "labels = (train_generator_top.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "#predictions= model.predict_generator(valid_generator_top, steps = nb_validation_samples // batch_size)\n",
    "#y_classes = predictions.argmax(axis=-1)\n",
    "#print(predictions.shape)\n",
    "#print (predictions)\n",
    "\n",
    "filenames=test_generator3.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.to_csv(\"results_forTestdata_3.csv\",index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#print (predictions)\\nimport sklearn as sk\\nfrom sklearn.metrics import confusion_matrix\\nfrom sklearn.metrics import classification_report\\nimport numpy as np\\n\\n#confusion_matrix(valid_generator_top.classes, y_classes)\\nprint('Confusion MatrixPredict...')\\ntest_generator3.reset()\\npredCM=model.predict_generator(test_generator3,verbose=1)\\ny_pred3 = predCM.argmax(axis=-1) #np.argmax(predictions, axis=1)\\nprint('Confusion Matrix')\\nprint(confusion_matrix(test_generator3.classes, y_pred3))\\nprint('Classification Report')\\ntarget_names = ['Depth1', 'Depth2', 'Depth3', 'Depth4']\\nprint(classification_report(test_generator3.classes, y_pred3, target_names=target_names))\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#print (predictions)\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "#confusion_matrix(valid_generator_top.classes, y_classes)\n",
    "print('Confusion MatrixPredict...')\n",
    "test_generator3.reset()\n",
    "predCM=model.predict_generator(test_generator3,verbose=1)\n",
    "y_pred3 = predCM.argmax(axis=-1) #np.argmax(predictions, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator3.classes, y_pred3))\n",
    "print('Classification Report')\n",
    "target_names = ['Depth1', 'Depth2', 'Depth3', 'Depth4']\n",
    "print(classification_report(test_generator3.classes, y_pred3, target_names=target_names))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
